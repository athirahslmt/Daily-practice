{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5bbf1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "712a3410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear combination (z) :  5.4\n"
     ]
    }
   ],
   "source": [
    "def neuron_output (x1, x2, w1, w2,b):\n",
    "    \"\"\"\"\"\n",
    "    A simple neuron :\n",
    "    z = W1*X1 + W2*X2 + b\n",
    "    Here we will NOT apply an activation yet, just return z\n",
    "    \"\"\"\n",
    "\n",
    "    z = w1*x1 + w2*x2 + b\n",
    "    return z\n",
    "\n",
    "x1 = 5 \n",
    "x2 = 2 \n",
    "\n",
    "w1 = 0.8\n",
    "w2 = 1.2\n",
    "b = -1.0\n",
    "\n",
    "z = neuron_output(x1, x2, w1, w2, b)\n",
    "print(\"Linear combination (z) : \", z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1355a4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : \n",
      " [[2.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "#5.1 Tiny 2 -layer neural network forward pass (no training)\n",
    "np.random.seed(42)\n",
    "\n",
    "#Input : 1 feature\n",
    "x = np.array([[2.0],\n",
    "              [1.0]]) #shape (2,1)\n",
    "\n",
    "print(f'x : \\n {x}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eddf03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W : \n",
      " [[ 0.49671415 -0.1382643 ]\n",
      " [ 0.64768854  1.52302986]\n",
      " [-0.23415337 -0.23413696]] \n",
      "B : \n",
      " [[ 1.57921282]\n",
      " [ 0.76743473]\n",
      " [-0.46947439]]\n"
     ]
    }
   ],
   "source": [
    "#Hidden layer : 3 neurons\n",
    "#3 rows of weight for 3 neuron\n",
    "# as many feature element as many column\n",
    "W1 = np.random.randn(3,2) #weights for hidden layer (1x3)\n",
    "b1 = np.random.randn(3,1) #bias for hidden layer (3x1)\n",
    "\n",
    "print(f'W : \\n {W1} \\nB : \\n {b1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf2a270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W2 : \n",
      " [[ 0.49671415 -0.1382643   0.64768854]]\n",
      " b2 : \n",
      "[[1.52302986]]\n"
     ]
    }
   ],
   "source": [
    "#Output layer : 1 neuron\n",
    "W2 = np.random.randn(1,3) # weights for output layer (1x3)\n",
    "b2 = np.random.randn(1,1) # bias for output ayer (1x1)\n",
    "\n",
    "print(f'W2 : \\n {W2}\\n b2 : \\n{b2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "812d241d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(z):\n",
    "    return np.maximum(0,z)\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd159a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z1 : \n",
      " [[-0.144836  ]\n",
      " [ 1.81840693]\n",
      " [-1.70244371]]\n",
      "a1 : [[0.        ]\n",
      " [1.81840693]\n",
      " [0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#Forward pass\n",
    "#Hidden layer\n",
    "z1 = np.dot(W1, x) +b #linear\n",
    "a1 = relu(z1) #activation\n",
    "\n",
    "print (f'z1 : \\n {z1}\\na1 : {a1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c9428d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z2 : \n",
      " [[ 0.49671415 -0.1382643   0.64768854]]\n",
      " a2 : \n",
      " [[0.78101807]]\n"
     ]
    }
   ],
   "source": [
    "#Output layer\n",
    "\n",
    "z2 = np.dot(W2, a1) + b2 # linear\n",
    "a2 = sigmoid(z2)\n",
    "\n",
    "print(f'z2 : \\n {W2}\\n a2 : \\n {a2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c5d05ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x:\n",
      " [[2.]\n",
      " [1.]]\n",
      "\n",
      "Hidden layer linear output (z1):\n",
      " [[-0.144836  ]\n",
      " [ 1.81840693]\n",
      " [-1.70244371]]\n",
      "\n",
      "Hidden layer activation (a1, after ReLU):\n",
      " [[0.        ]\n",
      " [1.81840693]\n",
      " [0.        ]]\n",
      "\n",
      "Output layer linear output (z2):\n",
      " [[1.27160909]]\n",
      "\n",
      "Final output (a2, after sigmoid – can be seen as probability):\n",
      " [[0.78101807]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Input x:\\n\", x)\n",
    "print(\"\\nHidden layer linear output (z1):\\n\", z1)\n",
    "print(\"\\nHidden layer activation (a1, after ReLU):\\n\", a1)\n",
    "print(\"\\nOutput layer linear output (z2):\\n\", z2)\n",
    "print(\"\\nFinal output (a2, after sigmoid – can be seen as probability):\\n\", a2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
